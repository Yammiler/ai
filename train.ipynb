{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPEdjeVyjWmjgxb23JBUlap"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qlqyingLLp2p","executionInfo":{"status":"ok","timestamp":1684170031455,"user_tz":-420,"elapsed":4274,"user":{"displayName":"kien Vu","userId":"04287862926629047297"}},"outputId":"ad0e2287-7ca5-4db2-c0b0-b9f9eef70f3d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/driver; to attempt to forcibly remount, call drive.mount(\"/content/driver\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/driver')"]},{"cell_type":"code","source":["import pandas as pd"],"metadata":{"id":"uxnMWYubMG12","executionInfo":{"status":"ok","timestamp":1684170035427,"user_tz":-420,"elapsed":1224,"user":{"displayName":"kien Vu","userId":"04287862926629047297"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["df_data = df_data = pd.read_excel('/content/driver/MyDrive/MAT308/data (2).xlsx')\n","del df_data['Unnamed: 2']"],"metadata":{"id":"5V6elzVqcuRu","executionInfo":{"status":"ok","timestamp":1684170039753,"user_tz":-420,"elapsed":1044,"user":{"displayName":"kien Vu","userId":"04287862926629047297"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["df_data"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"5Jy3c-6Qc7nE","executionInfo":{"status":"ok","timestamp":1684170043468,"user_tz":-420,"elapsed":5,"user":{"displayName":"kien Vu","userId":"04287862926629047297"}},"outputId":"393b4063-d585-4f89-967e-1902d2933865"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                Comment  Labels\n","0     máy bụi nhiều và nhìn hơi cũ. giá 170k thấy hơ...       0\n","1     Máy mới xài tạm ổn. Máy này xây hạt thành bột ...       0\n","2     Giao hàng nhanh, đúng lịch. Nhưng k có túi nil...       0\n","3     hài lòng hàng như quảng cáo cáo , nhưng có điề...       0\n","4            Nắp đậy không kín, xay bị văn bột ra ngoài       0\n","...                                                 ...     ...\n","1639  Được giới thiệu từ quyển Kinh doanh online trê...       1\n","1640  tôi đã từng đọc quyển sách khởi nghiệp bán lẻ ...       1\n","1641  Quả thật, sản phẩm nào cũng anh Phong cũng chấ...       1\n","1642  Thực sự rất bất ngờ với tốc độ giao của sách, ...       1\n","1643  Sách hay, đáng tiền.Trên lưng khổng tượng hướn...       1\n","\n","[1644 rows x 2 columns]"],"text/html":["\n","  <div id=\"df-3fbf5c76-4f64-42c3-895b-f283e9c4b536\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Comment</th>\n","      <th>Labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>máy bụi nhiều và nhìn hơi cũ. giá 170k thấy hơ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Máy mới xài tạm ổn. Máy này xây hạt thành bột ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Giao hàng nhanh, đúng lịch. Nhưng k có túi nil...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>hài lòng hàng như quảng cáo cáo , nhưng có điề...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Nắp đậy không kín, xay bị văn bột ra ngoài</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1639</th>\n","      <td>Được giới thiệu từ quyển Kinh doanh online trê...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1640</th>\n","      <td>tôi đã từng đọc quyển sách khởi nghiệp bán lẻ ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1641</th>\n","      <td>Quả thật, sản phẩm nào cũng anh Phong cũng chấ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1642</th>\n","      <td>Thực sự rất bất ngờ với tốc độ giao của sách, ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1643</th>\n","      <td>Sách hay, đáng tiền.Trên lưng khổng tượng hướn...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1644 rows × 2 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3fbf5c76-4f64-42c3-895b-f283e9c4b536')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-3fbf5c76-4f64-42c3-895b-f283e9c4b536 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-3fbf5c76-4f64-42c3-895b-f283e9c4b536');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["import re\n","\n","def standardize_data(row):\n","    # remove stopword\n","    # Remove . ? , at index final\n","    row = re.sub(r\"[\\.,\\?]+$-\", \"\", row)\n","    # Remove all . , \" ... in sentences\n","    row = row.replace(\",\", \" \").replace(\".\", \" \") \\\n","        .replace(\";\", \" \").replace(\"“\", \" \") \\\n","        .replace(\":\", \" \").replace(\"”\", \" \") \\\n","        .replace('\"', \" \").replace(\"'\", \" \") \\\n","        .replace(\"!\", \" \").replace(\"?\", \" \") \\\n","        .replace(\"-\", \" \").replace(\"?\", \" \")\n","\n","    row = row.lower()\n","    row = row.strip()\n","\n","    return row"],"metadata":{"id":"dX58JdAENHV8","executionInfo":{"status":"ok","timestamp":1684170048505,"user_tz":-420,"elapsed":643,"user":{"displayName":"kien Vu","userId":"04287862926629047297"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["pip install transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"twTwykj-QuBm","executionInfo":{"status":"ok","timestamp":1684170059628,"user_tz":-420,"elapsed":3356,"user":{"displayName":"kien Vu","userId":"04287862926629047297"}},"outputId":"d585edf3-1645-4ea2-e593-0b1a19cd2a8f"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.29.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.model_selection import cross_val_score\n","import torch\n","import transformers\n","from transformers import BertModel, BertTokenizer\n","import joblib"],"metadata":{"id":"g_gUsAgxQfyz","executionInfo":{"status":"ok","timestamp":1684170069344,"user_tz":-420,"elapsed":2266,"user":{"displayName":"kien Vu","userId":"04287862926629047297"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# load model BERT\n","model = BertModel.from_pretrained('bert-base-uncased')\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","\n","#encode lines\n","tokenized = df_data['Comment'].apply((lambda x: tokenizer.encode(x, add_special_tokens = True)))\n","print('encode',tokenized[1])\n","# decode\n","print('decode',tokenizer.decode(tokenized[1]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_vk0qO_KQnC9","executionInfo":{"status":"ok","timestamp":1684170087842,"user_tz":-420,"elapsed":11576,"user":{"displayName":"kien Vu","userId":"04287862926629047297"}},"outputId":"0cd13d1c-6ef6-4c2e-fcdf-d3ccd128378e"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["encode [101, 2089, 25175, 1060, 4886, 17214, 2006, 1012, 2089, 29349, 1060, 4710, 6045, 2084, 2232, 28516, 18699, 2319, 2232, 1010, 18699, 5575, 11265, 2226, 14163, 2239, 1060, 4710, 18699, 26230, 2368, 10189, 2084, 2232, 8945, 11320, 2239, 16215, 2072, 1047, 19991, 1102, 19098, 2278, 1010, 2079, 2053, 12170, 17710, 2102, 12436, 2080, 11320, 10448, 4830, 2080, 1010, 12731, 3070, 2089, 10023, 26230, 3388, 1013, 1011, 2154, 1102, 9013, 11586, 2232, 12436, 2080, 2089, 11265, 2078, 1047, 6806, 2050, 2310, 8254, 2232, 102]\n","decode [CLS] may moi xai tam on. may nay xay hat thanh bot nhanh, nhung neu muon xay nhuyen hon thanh bo luon thi khong đuoc, do no bi ket vao luoi dao, cung maykhuyet / - day đien dinh vao may nen khoa ve sinh [SEP]\n"]}]},{"cell_type":"code","source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"metadata":{"id":"SVB9aFiyugqs","executionInfo":{"status":"ok","timestamp":1684170098567,"user_tz":-420,"elapsed":1539,"user":{"displayName":"kien Vu","userId":"04287862926629047297"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["#get all label \n","labels = np.zeros(len(df_data['Labels']))\n","for i in range(1,len(df_data['Labels'])):\n","    labels[i] = df_data['Labels'][i]\n","print('labels shape:', labels.shape)\n","\n","def pretrainmodel_bert(tokenized):\n","  # get lenght max of tokenized\n","  max_len = 0\n","  for i in tokenized.values:\n","      if len(i) > max_len:\n","          max_len = len(i)\n","  print('max len:', max_len)\n","\n","  # if lenght of tokenized not equal max_len , so padding value 0\n","  padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])\n","  print('padded:', padded[1])\n","  print('len padded:', padded.shape)\n","\n","  #get attention mask ( 0: not has word, 1: has word)\n","  attention_mask = np.where(padded ==0, 0,1)\n","  print('attention mask:', attention_mask[1])\n","\n","  # Convert input to tensor\n","  padded = torch.tensor(padded)\n","  attention_mask = torch.tensor(attention_mask)\n","\n","\n","  # Train model\n","  batch = 26\n","  batch_size = 64\n","  list = []\n","  for i in range(1,batch+1):\n","    index_beffor = (i-1) * batch_size \n","    if i == 26:\n","      index_affter == 1644\n","    index_affter = i * batch_size\n","    input_ids_batch = padded[index_beffor:index_affter]\n","    attention_mask_batch = attention_mask[index_beffor:index_affter]\n","    with torch.no_grad():\n","        last_hidden_states = model(input_ids = input_ids_batch, attention_mask = attention_mask_batch)\n","    #     print('last hidden states:', last_hidden_states)\n","\n","    features = last_hidden_states[0][:,0,:].numpy()\n","    list.append(features)\n","    print(\"batch \", i)\n","\n","    # concat and reshape ndarray\n","  data_train = list[0]\n","  for i in range(1, len(list)):\n","    data_train = np.concatenate((data_train, list[i]), axis=0)\n","  data_train = np.reshape(data_train,(1644, 768))\n","  return data_train\n","\n","data_train = pretrainmodel_bert(tokenized)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zyPMjqEZSzqW","outputId":"ee786d73-f0ce-4d27-fa54-b1ad00be3e29","executionInfo":{"status":"ok","timestamp":1684171703145,"user_tz":-420,"elapsed":1458444,"user":{"displayName":"kien Vu","userId":"04287862926629047297"}}},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["labels shape: (1644,)\n","max len: 258\n","padded: [  101  2089 25175  1060  4886 17214  2006  1012  2089 29349  1060  4710\n","  6045  2084  2232 28516 18699  2319  2232  1010 18699  5575 11265  2226\n"," 14163  2239  1060  4710 18699 26230  2368 10189  2084  2232  8945 11320\n","  2239 16215  2072  1047 19991  1102 19098  2278  1010  2079  2053 12170\n"," 17710  2102 12436  2080 11320 10448  4830  2080  1010 12731  3070  2089\n"," 10023 26230  3388  1013  1011  2154  1102  9013 11586  2232 12436  2080\n","  2089 11265  2078  1047  6806  2050  2310  8254  2232   102     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0]\n","len padded: (1644, 258)\n","attention mask: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"," 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"," 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n","batch  1\n","batch  2\n","batch  3\n","batch  4\n","batch  5\n","batch  6\n","batch  7\n","batch  8\n","batch  9\n","batch  10\n","batch  11\n","batch  12\n","batch  13\n","batch  14\n","batch  15\n","batch  16\n","batch  17\n","batch  18\n","batch  19\n","batch  20\n","batch  21\n","batch  22\n","batch  23\n","batch  24\n","batch  25\n","batch  26\n"]}]},{"cell_type":"code","source":["X_train, X_test, y_train, y_test = train_test_split(data_train, labels)\n","\n","cl = LogisticRegression()\n","cl.fit(X_train, y_train)\n","\n","# Save model\n","joblib.dump(cl, 'save_model.pkl')\n","sc = cl.score(X_test, y_test)\n","print('score:', sc)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ul_qPjg_ZJcl","executionInfo":{"status":"ok","timestamp":1684171973413,"user_tz":-420,"elapsed":1049,"user":{"displayName":"kien Vu","userId":"04287862926629047297"}},"outputId":"351498e5-582f-4fc8-947a-1c9e49cce321"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["score: 0.7931873479318735\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n"]}]},{"cell_type":"code","source":["\n","ls"],"metadata":{"id":"4GxYwGVla2aN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684171869897,"user_tz":-420,"elapsed":895,"user":{"displayName":"kien Vu","userId":"04287862926629047297"}},"outputId":"11a1f12b-b1db-4860-a60c-747669807ed3"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["'data (2).xlsx'   model_world2vec.ipynb   train.ipynb   word2vec.model\n"]}]},{"cell_type":"code","source":["cd /content/driver/MyDrive/MAT308"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-prAS9VeACyH","executionInfo":{"status":"ok","timestamp":1684171866440,"user_tz":-420,"elapsed":551,"user":{"displayName":"kien Vu","userId":"04287862926629047297"}},"outputId":"93ab8091-afda-4770-f97f-f606cb030a4c"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/driver/MyDrive/MAT308\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"NTwgkL0EAEgQ"},"execution_count":null,"outputs":[]}]}